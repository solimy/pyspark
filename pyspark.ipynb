{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['SPARK_HOME'] = '/usr/local/bin/spark-3.0.1-bin-hadoop3.2'\n",
    "os.environ['PYTHONPATH'] = f'{os.environ[\"SPARK_HOME\"]}/python:{os.environ[\"SPARK_HOME\"]}/python/build:{os.environ[\"PYTHONPATH\"]}'\n",
    "os.environ['PYTHONPATH'] = f'{os.environ[\"SPARK_HOME\"]}/python/lib/pyspark.zip:{os.environ[\"PYTHONPATH\"]}'\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "conf = SparkConf().setAppName('appName').setMaster('local')\n",
    "spark_context = SparkContext(conf=conf)\n",
    "#data = range(10)\n",
    "#dist_data = sc.parallelize(data)\n",
    "#print(dist_data.reduce(lambda a, b: a+b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark_session = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .master(\"local\")\n",
    "#    .appName(\"Word Count\")\n",
    "#    .config(\"spark.some.config.option\", \"some-value\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {\n",
    "    'header': True,\n",
    "    'inferSchema': True,\n",
    "}\n",
    "sdf = spark_session.read.options(**options).csv('exemple.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import databricks.koalas as ks\n",
    "kdf = sdf.to_koalas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'databricks.koalas.frame.DataFrame'>\nIndex: 5000 entries, 0 to 4999\nData columns (total 45 columns):\n #   Column                              Non-Null Count  Dtype  \n---  ------                              --------------  -----  \n 0   date                                5000 non-null   object \n 1   location_key                        5000 non-null   object \n 2   country_code                        5000 non-null   object \n 3   country_name                        5000 non-null   object \n 4   subregion1_code                     5000 non-null   object \n 5   subregion1_name                     5000 non-null   object \n 6   subregion2_code                     5000 non-null   int32  \n 7   subregion2_name                     5000 non-null   object \n 8   iso_3166_1_alpha_2                  5000 non-null   object \n 9   iso_3166_1_alpha_3                  5000 non-null   object \n 10  aggregation_level                   5000 non-null   int32  \n 11  new_confirmed                       3849 non-null   int32  \n 12  new_deceased                        3849 non-null   int32  \n 13  new_recovered                       0 non-null      object \n 14  new_tested                          0 non-null      object \n 15  cumulative_confirmed                3864 non-null   int32  \n 16  cumulative_deceased                 3864 non-null   int32  \n 17  cumulative_recovered                0 non-null      object \n 18  cumulative_tested                   0 non-null      object \n 19  new_hospitalized_patients           0 non-null      object \n 20  new_intensive_care_patients         0 non-null      object \n 21  new_ventilator_patients             0 non-null      object \n 22  cumulative_hospitalized_patients    0 non-null      object \n 23  cumulative_intensive_care_patients  0 non-null      object \n 24  cumulative_ventilator_patients      0 non-null      object \n 25  current_hospitalized_patients       0 non-null      object \n 26  current_intensive_care_patients     0 non-null      object \n 27  current_ventilator_patients         0 non-null      object \n 28  mobility_transit_stations           1696 non-null   int32  \n 29  mobility_retail_and_recreation      2740 non-null   int32  \n 30  mobility_grocery_and_pharmacy       2456 non-null   int32  \n 31  mobility_parks                      2031 non-null   int32  \n 32  mobility_residential                2397 non-null   int32  \n 33  mobility_workplaces                 3827 non-null   int32  \n 34  wikidata_id                         5000 non-null   object \n 35  datacommons_id                      5000 non-null   object \n 36  openstreetmap_id                    5000 non-null   int32  \n 37  latitude                            5000 non-null   float64\n 38  longitude                           5000 non-null   float64\n 39  location_geometry                   5000 non-null   object \n 40  average_temperature_celsius         4940 non-null   float64\n 41  minimum_temperature_celsius         4940 non-null   float64\n 42  maximum_temperature_celsius         4940 non-null   float64\n 43  rainfall_mm                         4940 non-null   float64\n 44  snowfall_mm                         479 non-null    float64\ndtypes: float64(7), int32(13), object(25)"
     ]
    }
   ],
   "source": [
    "kdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "109558"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "kdf.query('country_code == \"US\"').cumulative_deceased.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}